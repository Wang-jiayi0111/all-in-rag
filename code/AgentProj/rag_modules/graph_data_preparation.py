"""
å›¾æ•°æ®åº“æ•°æ®å‡†å¤‡æ¨¡å—
"""

import logging
import hashlib
import json
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from pathlib import Path

from neo4j import GraphDatabase
from langchain_core.documents import Document

logger = logging.getLogger(__name__)

@dataclass
class GraphNode:
    """å›¾èŠ‚ç‚¹æ•°æ®ç»“æ„"""
    node_id: str
    labels: List[str]
    name: str
    properties: Dict[str, Any]

@dataclass
class GraphRelation:
    """å›¾å…³ç³»æ•°æ®ç»“æ„"""
    start_node_id: str
    end_node_id: str
    relation_type: str
    properties: Dict[str, Any]

class GraphDataPreparationModule:
    """å›¾æ•°æ®åº“æ•°æ®å‡†å¤‡æ¨¡å— - ä»Neo4jè¯»å–æ•°æ®å¹¶è½¬æ¢ä¸ºæ–‡æ¡£"""
    
    def __init__(self, data_path: str, uri: str, user: str, password: str, database: str = "neo4j"):
        """
        åˆå§‹åŒ–å›¾æ•°æ®åº“è¿æ¥
        
        Args:
            uri: Neo4jè¿æ¥URI
            user: ç”¨æˆ·å
            password: å¯†ç 
            database: æ•°æ®åº“åç§°
        """
        self.uri = uri
        self.user = user
        self.password = password
        self.database = database
        self.driver = None
        self.documents: List[Document] = []
        self.chunks: List[Document] = []
        self.recipes: List[GraphNode] = []
        self.ingredients: List[GraphNode] = []
        self.cooking_steps: List[GraphNode] = []

        self.data_path = data_path
        self.parent_child_map: Dict[str, str] = {}

        # åˆå§‹åŒ–æ–‡ä»¶æ˜ å°„å­—å…¸
        self.file_map: Dict[str, Path] = {}
        # å»ºç«‹æœ¬åœ°æ–‡ä»¶ç´¢å¼•
        if self.data_path:
            self._build_local_file_map()
        
        self._connect()
        
    def _build_local_file_map(self):
        """æ‰«ææœ¬åœ°ç›®å½•ï¼Œå»ºç«‹{èœåï¼šæ–‡ä»¶è·¯å¾„} çš„æ˜ å°„"""
        if not self.data_path:
            return
        
        logger.info(f"æ­£åœ¨æ‰«ææœ¬åœ°æ–‡ä»¶æ˜ å°„ï¼š{self.data_path}")
        path_obj = Path(self.data_path)
        
        count = 0
        for file_path in path_obj.rglob("*.md"):
            # å‡è®¾æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰å³ä¸ºèœå
            dish_name = file_path.stem 
            self.file_map[dish_name] = file_path
            count += 1
        logger.info(f"å·²å»ºç«‹ {count} ä¸ªæœ¬åœ°æ–‡ä»¶çš„ç´¢å¼•æ˜ å°„")
    
    def _connect(self):
        """å»ºç«‹Neo4jè¿æ¥"""
        try:
            self.driver = GraphDatabase.driver(
                self.uri, 
                auth=(self.user, self.password),
                database=self.database
            )
            logger.info(f"å·²è¿æ¥åˆ°Neo4jæ•°æ®åº“: {self.uri}")
            
            # æµ‹è¯•è¿æ¥
            with self.driver.session() as session:
                result = session.run("RETURN 1 as test")
                test_result = result.single()
                if test_result:
                    logger.info("Neo4jè¿æ¥æµ‹è¯•æˆåŠŸ")
                    
        except Exception as e:
            logger.error(f"è¿æ¥Neo4jå¤±è´¥: {e}")
            raise
    
    def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if hasattr(self, 'driver') and self.driver:
            self.driver.close()
            logger.info("Neo4jè¿æ¥å·²å…³é—­")
    
    def load_graph_data(self) -> Dict[str, Any]:
        """
        ä»Neo4jåŠ è½½å›¾æ•°æ®ï¼ˆæŠ½å–â€”â€”ä½¿ç”¨ Cypher è¯­å¥æŠ½å–èœè°±ã€é£Ÿæã€æ­¥éª¤çš„æ•°æ®ï¼‰
        
        Returns:
            åŒ…å«èŠ‚ç‚¹ï¼ˆé£Ÿæï¼‰å’Œå…³ç³»ï¼ˆæ­¥éª¤ï¼‰çš„æ•°æ®å­—å…¸
        """
        logger.info("æ­£åœ¨ä»Neo4jåŠ è½½å›¾æ•°æ®...")
        
        with self.driver.session() as session:
            # åŠ è½½æ‰€æœ‰èœè°±èŠ‚ç‚¹ï¼Œä»Categoryå…³ç³»ä¸­è¯»å–åˆ†ç±»ä¿¡æ¯
            recipes_query = """
            MATCH (r:Recipe)
            WHERE r.nodeId >= '200000000'
            OPTIONAL MATCH (r)-[:BELONGS_TO_CATEGORY]->(c:Category)
            WITH r, collect(c.name) as categories
            RETURN r.nodeId as nodeId, labels(r) as labels, r.name as name, 
                   properties(r) as originalProperties,
                   CASE WHEN size(categories) > 0 
                        THEN categories[0] 
                        ELSE COALESCE(r.category, 'æœªçŸ¥') END as mainCategory,
                   CASE WHEN size(categories) > 0 
                        THEN categories 
                        ELSE [COALESCE(r.category, 'æœªçŸ¥')] END as allCategories
            ORDER BY r.nodeId
            """
            
            result = session.run(recipes_query)
            self.recipes = []
            for record in result:
                # åˆå¹¶åŸå§‹å±æ€§å’Œæ–°çš„åˆ†ç±»ä¿¡æ¯
                properties = dict(record["originalProperties"])
                properties["category"] = record["mainCategory"]
                properties["all_categories"] = record["allCategories"]
                
                node = GraphNode(
                    node_id=record["nodeId"],
                    labels=record["labels"],
                    name=record["name"],
                    properties=properties
                )
                self.recipes.append(node)
            
            logger.info(f"åŠ è½½äº† {len(self.recipes)} ä¸ªèœè°±èŠ‚ç‚¹")
            
            # åŠ è½½æ‰€æœ‰é£ŸæèŠ‚ç‚¹
            ingredients_query = """
            MATCH (i:Ingredient)
            WHERE i.nodeId >= '200000000'
            RETURN i.nodeId as nodeId, labels(i) as labels, i.name as name,
                   properties(i) as properties
            ORDER BY i.nodeId
            """
            
            result = session.run(ingredients_query)
            self.ingredients = []
            for record in result:
                node = GraphNode(
                    node_id=record["nodeId"],
                    labels=record["labels"],
                    name=record["name"],
                    properties=record["properties"]
                )
                self.ingredients.append(node)
            
            logger.info(f"åŠ è½½äº† {len(self.ingredients)} ä¸ªé£ŸæèŠ‚ç‚¹")
            
            # åŠ è½½æ‰€æœ‰çƒ¹é¥ªæ­¥éª¤èŠ‚ç‚¹
            steps_query = """
            MATCH (s:CookingStep)
            WHERE s.nodeId >= '200000000'
            RETURN s.nodeId as nodeId, labels(s) as labels, s.name as name,
                   properties(s) as properties
            ORDER BY s.nodeId
            """
            
            result = session.run(steps_query)
            self.cooking_steps = []
            for record in result:
                node = GraphNode(
                    node_id=record["nodeId"],
                    labels=record["labels"],
                    name=record["name"],
                    properties=record["properties"]
                )
                self.cooking_steps.append(node)
            
            logger.info(f"åŠ è½½äº† {len(self.cooking_steps)} ä¸ªçƒ¹é¥ªæ­¥éª¤èŠ‚ç‚¹")
        
        return {
            'recipes': len(self.recipes),
            'ingredients': len(self.ingredients),
            'cooking_steps': len(self.cooking_steps)
        }
    
    def build_recipe_documents(self) -> List[Document]:
        """
        æ„å»ºèœè°±æ–‡æ¡£ï¼Œé›†æˆç›¸å…³çš„é£Ÿæå’Œæ­¥éª¤ä¿¡æ¯ï¼ˆè½¬æ¢â€”â€”å°†load_graph_dataæå–çš„ä¿¡æ¯æ„å»ºæˆDocumentç±»å‹ï¼‰
        
        Returns:
            ç»“æ„åŒ–çš„èœè°±æ–‡æ¡£åˆ—è¡¨
        """
        logger.info("æ­£åœ¨æ„å»ºèœè°±æ–‡æ¡£...")
        
        documents = []
        
        with self.driver.session() as session:
            for recipe in self.recipes:
                try:
                    recipe_id = recipe.node_id
                    recipe_name = recipe.name
                    
                    # è·å–èœè°±çš„ç›¸å…³é£Ÿæ
                    ingredients_query = """
                    MATCH (r:Recipe {nodeId: $recipe_id})-[req:REQUIRES]->(i:Ingredient)
                    RETURN i.name as name, i.category as category, 
                           req.amount as amount, req.unit as unit,
                           i.description as description
                    ORDER BY i.name
                    """
                    
                    ingredients_result = session.run(ingredients_query, {"recipe_id": recipe_id})
                    ingredients_list = list(ingredients_result)
                    ingredients_count = len(ingredients_list)

                    # è·å–èœè°±çš„çƒ¹é¥ªæ­¥éª¤
                    steps_query = """
                    MATCH (r:Recipe {nodeId: $recipe_id})-[c:CONTAINS_STEP]->(s:CookingStep)
                    RETURN s.name
                    """
                    
                    steps_result = session.run(steps_query, {"recipe_id": recipe_id})
                    steps_list = list(steps_result)
                    steps_count = len(steps_list)

                    # -------------------------------------------------------
                    # æ­¥éª¤ 2: æ„å»º page_content 
                    # -------------------------------------------------------
                    full_content = ""
                    source_type = "neo4j_generated"

                    # è¯»å–æœ¬åœ°.mdæ–‡ä»¶
                    if recipe_name in self.file_map:
                        try:
                            file_path = self.file_map[recipe_name]
                            with open(file_path, 'r', encoding='utf-8') as f:
                                full_content = f.read()
                            source_type = "local_file_enhanced"
                        except Exception as e:
                            logger.warning(f"è¯»å–æœ¬åœ°æ–‡ä»¶å¤±è´¥ {recipe_name}: {e}")
                    
                    # ç”¨Neo4jæ‹¼æ¥
                    if not full_content:
                        logger.warning(f"[{recipe_name}] æœªæ‰¾åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œä½¿ç”¨ Neo4j æ•°æ®æ‹¼æ¥")
                        content_parts = [f"# {recipe_name}"]
                        if recipe.properties.get("description"):
                            content_parts.append(f"\n## èœå“æè¿°\n{recipe.properties['description']}")
                        
                        # ç®€æ˜“æ‹¼æ¥é£Ÿæ
                        if ingredients_list:
                            content_parts.append("\n## æ‰€éœ€é£Ÿæ")
                            for ing in ingredients_list:
                                content_parts.append(f"- {ing['name']}")
                                
                        full_content = "\n".join(content_parts)
                        source_type = "neo4j_fallback"
                    
                    # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
                    doc = Document(
                        page_content=full_content,
                        metadata={
                            # --- æ ¸å¿ƒæ ‡è¯† ---
                            "node_id": recipe_id,
                            "recipe_name": recipe_name,
                            "node_type": "Recipe",
                            "content_source": source_type,

                            # --- ä¸šåŠ¡å±æ€§ ---
                            "category": recipe.properties.get("category", "æœªçŸ¥"),
                            "cuisine_type": recipe.properties.get("cuisineType", "æœªçŸ¥"),
                            "difficulty": recipe.properties.get("difficulty", 0),
                            "doc_type": "recipe",

                            # --- ç»Ÿè®¡å±æ€§ ---
                            "ingredients_count": ingredients_count,
                            "steps_count": steps_count,

                            # --- è¯¦æƒ…å±æ€§ ---
                            "prep_time": recipe.properties.get("prepTime", ""),
                            "cook_time": recipe.properties.get("cookTime", ""),
                            "servings": recipe.properties.get("servings", ""),
                            "content_length": len(full_content)
                        }
                    )
                    
                    documents.append(doc)
                    
                except Exception as e:
                    logger.warning(f"æ„å»ºèœè°±æ–‡æ¡£å¤±è´¥ {recipe_name} (ID: {recipe_id}): {e}")
                    continue
        
        self.documents = documents
        logger.info(f"æˆåŠŸæ„å»º {len(documents)} ä¸ªèœè°±æ–‡æ¡£")
        return documents


    def chunk_documents(self, chunk_size: int = 500, chunk_overlap: int = 50) -> List[Document]:
        """
        å¯¹æ–‡æ¡£è¿›è¡Œåˆ†å—å¤„ç†
        
        Args:
            chunk_size: åˆ†å—å¤§å°
            chunk_overlap: é‡å å¤§å°
            
        Returns:
            åˆ†å—åçš„æ–‡æ¡£åˆ—è¡¨
        """
        logger.info(f"æ­£åœ¨è¿›è¡Œæ–‡æ¡£åˆ†å—ï¼Œå—å¤§å°: {chunk_size}, é‡å : {chunk_overlap}")
        
        if not self.documents:
            raise ValueError("è¯·å…ˆæ„å»ºdocument")
        
        chunks = []
        chunk_id = 0
        
        for doc in self.documents:
            content = doc.page_content
            
            # ç®€å•çš„æŒ‰é•¿åº¦åˆ†å—
            if len(content) <= chunk_size:
                # å†…å®¹è¾ƒçŸ­ï¼Œä¸éœ€è¦åˆ†å—
                chunk = Document(
                    page_content=content,
                    metadata={
                        **doc.metadata,
                        "chunk_id": f"{doc.metadata['node_id']}_chunk_{chunk_id}",
                        "parent_id": doc.metadata["node_id"],
                        "chunk_index": 0,
                        "total_chunks": 1,
                        "chunk_size": len(content),
                        "doc_type": "chunk"
                    }
                )
                chunks.append(chunk)
                chunk_id += 1
            else:
                # æŒ‰ç« èŠ‚åˆ†å—ï¼ˆåŸºäºæ ‡é¢˜ï¼‰
                sections = content.split('\n## ')
                if len(sections) <= 1:
                    # æ²¡æœ‰äºŒçº§æ ‡é¢˜ï¼ŒæŒ‰é•¿åº¦å¼ºåˆ¶åˆ†å—
                    total_chunks = (len(content) - 1) // (chunk_size - chunk_overlap) + 1
                    
                    for i in range(total_chunks):
                        start = i * (chunk_size - chunk_overlap)
                        end = min(start + chunk_size, len(content))
                        
                        chunk_content = content[start:end]
                        
                        chunk = Document(
                            page_content=chunk_content,
                            metadata={
                                **doc.metadata,
                                "chunk_id": f"{doc.metadata['node_id']}_chunk_{chunk_id}",
                                "parent_id": doc.metadata["node_id"],
                                "chunk_index": i,
                                "total_chunks": total_chunks,
                                "chunk_size": len(chunk_content),
                                "doc_type": "chunk"
                            }
                        )
                        chunks.append(chunk)
                        chunk_id += 1
                else:
                    # æŒ‰ç« èŠ‚åˆ†å—
                    total_chunks = len(sections)
                    for i, section in enumerate(sections):
                        if i == 0:
                            # ç¬¬ä¸€ä¸ªéƒ¨åˆ†åŒ…å«æ ‡é¢˜
                            chunk_content = section
                        else:
                            # å…¶ä»–éƒ¨åˆ†æ·»åŠ ç« èŠ‚æ ‡é¢˜
                            chunk_content = f"## {section}"
                        
                        chunk = Document(
                            page_content=chunk_content,
                            metadata={
                                **doc.metadata,
                                "chunk_id": f"{doc.metadata['node_id']}_chunk_{chunk_id}",
                                "parent_id": doc.metadata["node_id"],
                                "chunk_index": i,
                                "total_chunks": total_chunks,
                                "chunk_size": len(chunk_content),
                                "doc_type": "chunk",
                                "section_title": section.split('\n')[0] if i > 0 else "ä¸»æ ‡é¢˜"
                            }
                        )
                        chunks.append(chunk)
                        chunk_id += 1
        
        self.chunks = chunks
        logger.info(f"æ–‡æ¡£åˆ†å—å®Œæˆï¼Œå…±ç”Ÿæˆ {len(chunks)} ä¸ªå—")
        return chunks
    
    def get_statistics(self) -> Dict[str, Any]:
        """
        è·å–æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        stats = {
            'total_recipes': len(self.recipes),
            'total_ingredients': len(self.ingredients),
            'total_cooking_steps': len(self.cooking_steps),
            'total_documents': len(self.documents),
            'total_chunks': len(self.chunks)
        }
        
        if self.documents:
            # åˆ†ç±»ç»Ÿè®¡
            categories = {}
            cuisines = {}
            difficulties = {}
            
            for doc in self.documents:
                category = doc.metadata.get('category', 'æœªçŸ¥')
                categories[category] = categories.get(category, 0) + 1
                
                cuisine = doc.metadata.get('cuisine_type', 'æœªçŸ¥')
                cuisines[cuisine] = cuisines.get(cuisine, 0) + 1
                
                difficulty = doc.metadata.get('difficulty', 0)
                difficulties[str(difficulty)] = difficulties.get(str(difficulty), 0) + 1
            
            stats.update({
                'categories': categories,
                'cuisines': cuisines,
                'difficulties': difficulties,
                'avg_content_length': sum(doc.metadata.get('content_length', 0) for doc in self.documents) / len(self.documents),
                'avg_chunk_size': sum(chunk.metadata.get('chunk_size', 0) for chunk in self.chunks) / len(self.chunks) if self.chunks else 0
            })
        
        return stats
    
    def print_graph_stats(self):
        with self.driver.session() as session:
            # æŸ¥è¯¢èŠ‚ç‚¹
            node_count = session.run("MATCH (n) RETURN count(n) AS count").single()["count"]
            # æŸ¥è¯¢è¾¹
            rel_count = session.run("MATCH ()-[r]->() RETURN count(r) AS count").single()["count"]
            
            print(f"âœ… å›¾è°±ç»Ÿè®¡å®Œæ¯•ï¼š")
            print(f"ğŸ“Š æ€»èŠ‚ç‚¹æ•° (Nodes): {node_count}")
            print(f"ğŸ”— æ€»è¾¹æ•° (Edges): {rel_count}")
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼Œç¡®ä¿å…³é—­è¿æ¥"""
        self.close() 